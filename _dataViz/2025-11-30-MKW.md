---
title: "Mario Kart World Character Combo"
tags: datasci clustering artsci gaming
article_header:
  type: overlay
  theme: dark
  background_image:
    gradient: 'linear-gradient(135deg, rgba(0, 0, 0 , .4), rgba(0, 0, 0, .4))'
    src: /media/mkw/ban.png
cover: /media/mkw/select03.png
---

Choosing a mario kart world character and vehicle combination the stats way.

<br>

<!--more-->

With 50 playable characters and 40 vehicles we have a total of 2000 possible combinations in [Mario Kart World](https://www.nintendo.com/us/store/products/mario-kart-world-switch-2/?srsltid=AfmBOor1qRSsk4Afg6UtUKV8_qoM5ySLO1iM22xT2n3SV-hpe4kxBDJE), which makes it a bit daunting to select a good combination from the lot. This post tries to make the exploration a bit more attainable.

<center><a href='/media/mkw/parallel.html'><img width="100%" src="/media/mkw/select01.png"></a></center>

# Intro

It is no secret that I am a huge Mario Kart fan so I got the game upon release with my Switch 2 and started playing with my preferred [MK8W speedrunning combo](https://chipdelmal.github.io/dataViz/2020-07-15-MK8D1.html) `Rosalina + BiddyBuggy` and more often experimenting with `Rosalina + Baby Blooper`, but playing through the Grand Prix and Knockout Tours I found some particular ones slightly harder than others and couldn't quite put my hand on why (specially the ones with more water tracks). After giving it some time and thanks to the work of people in the community ([see 'data sources'](#code-repo-and-data-sources)) I decided to have a look at the mystery to figure out a balanced combination that matched well my playstyle whilst getting to grips with the new mechanics.

# Code Dev

## Dataset

As I mentioned in the [intro](#intro), I didn't obtain the stats myself so please have a look at the original [sources](#code-repo-and-data-sources) and support the community if you can! I decided to use [this table](https://docs.google.com/spreadsheets/d/1t3BeXH3shj6Rh7x0ROFD81ZBxyumQFs9pebbnYcfWi4/edit?gid=735843013#gid=735843013) as source as it was relatively easy to transcribe into a more usable couple or CSV files. There was no real magic into this, other than copying everything over, and making it a dense, consistent set. A snippet of the [characters CSV](https://github.com/Chipdelmal/MKW_ParallelPlot/blob/main/data/CharacterStats.csv) looks like this:

```csv
Character,SpSolid,SpCoarse,SpLiquid,Accel,MiniT,WeightCoin,HdSolid,HdCoarse,HdLiquid
Baby Peach,0,0,0,7,4,0,6,6,6
Swooper,0,0,0,7,4,0,6,6,6
Para Biddybud,0,0,0,7,4,0,6,6,6
...
Rosalina,4,4,5,2,0,5,1,1,3
Pianta,5,5,6,1,0,6,0,0,2
Bowser,6,6,6,0,0,7,0,0,0
```

Whereas a segment of the [vehicles CSV](https://github.com/Chipdelmal/MKW_ParallelPlot/blob/main/data/KartStats.csv) ones follows:

```csv
Character,SpSolid,SpCoarse,SpLiquid,Accel,MiniT,WeightCoin,HdSolid,HdCoarse,HdLiquid
Mach Rocket,6,1,1,-7,-7,0,10,6,6
Baby Blooper,7,2,2,-6,-6,1,9,5,5
Biddybuggy,1,6,1,7,7,1,5,9,5
...
Standard Kart,5,5,5,5,5,2,5,5,5
Plushbuggy,5,5,5,5,5,2,5,5,5
Stellar Sled,6,8,11,0,0,5,1,2,8
```

With these two files we are all set to keep moving along in our analysis!

## Clustering

The initial thought I had was to do some stat-based clustering to identify combinations that are similar to the one I was using (`Rosalina - Baby Blooper`). The first step, was to read both CSV files and list of all character - kart combinations, which can be done with:

```python
###############################################################################
# Read files in
###############################################################################
(dfChr, dfKrt) = [
    pd.read_csv(path.join(PT_DTA, fn)).set_index('Character')
    for fn in ('CharacterStats.csv', 'KartStats.csv')
]
###############################################################################
# Get Combinations
###############################################################################
(CHARS, KARTS) = (list(dfChr.index), list(dfKrt.index))
COMBOS = list(product(CHARS, KARTS))
dfCmb = pd.DataFrame({
    f'{c} - {k}':  dfChr.loc[c]+dfKrt.loc[k]
    for (c, k) in COMBOS
}).T
```

Where we get the sum of stats for the kart and character in each one of the available options. With this in place, we can pick whichever clustering algorithm we prefer. In this case, I chose [scikit-learn's](https://scikit-learn.org/stable/) `AgglomerativeClustering` but it could very well be `KMeans`, `DBSCAN`, or any other. With this, we now select 200 as the number of different clusters to identify, so that we get a ten-fold reduction in the number of options.

```python
###############################################################################
# Cluster
###############################################################################
cFun = AgglomerativeClustering(n_clusters=NCST)
cluster_labels = cFun.fit_predict(dfCmb)
clList= list(zip(dfCmb.index, cluster_labels))
values = set(map(lambda x:x[1], clList))
clustersList = [[y[0] for y in clList if y[1]==x] for x in values]
```

We now serialize our structures to disk, for some later use:

```python
pkl.dump(clustersList, open(path.join(PT_CLS, 'lst_clusters.pkl'), 'wb'))
pkl.dump(clList, open(path.join(PT_CLS, 'lst_clustersID.pkl'), 'wb'))
```

The complete clustering code can be found [here](https://github.com/Chipdelmal/MKW_ParallelPlot/blob/main/clustering.py).

## HiPlot

In looking at the stats I started thinking of using parallel plots to visualize the high dimensional dataset. Initially, I tried using plotly for this but it was quickly apparent that it was not good enough for the application; this is when I came across [hiplot](https://facebookresearch.github.io/hiplot/), so I decided to take it for a spin. One clear advantage of this package is that it generates a [standalone HTML file](https://github.com/Chipdelmal/MKW_ParallelPlot/blob/main/plots/parallel.html) that can easily be shared and embedded.

```python
###############################################################################
# HiPlot
###############################################################################
exp = hip.Experiment.from_dataframe(dfCmb.reset_index())
exp.colormap = "interpolateSinebow"
exp.display_data(hip.Displays.PARALLEL_PLOT).update({
    'hide': ['uid', 'from_uid', 'Grp', 'Kart', 'Racer'],
    'order': cSort
})
exp.display_data(hip.Displays.TABLE).update({
    'hide': ['index', 'uid', 'from_uid'],
    'order': cSort[::-1]
})
exp.display(force_full_width=True)
_ = exp.to_html(path.join(cst.PT_PLT, 'parallel.html'))
```

Now, the [hiplot](https://facebookresearch.github.io/hiplot/) framework is quirky and a bit obscure in its documentation so I couldn't get any custom color palette to work but here are some snapshots of the [standalone HTML file](https://github.com/Chipdelmal/MKW_ParallelPlot/blob/main/plots/parallel.html), which can be readily [downloaded](https://github.com/Chipdelmal/MKW_ParallelPlot/blob/main/plots/parallel.html) and run in any browser:

<!-- <div class="swiper my-3 swiper-demo swiper-demo--0">
  <div class="swiper__wrapper">
    <div class="swiper__slide"><img src="/media/mkw/select03.png" style="width:100%;"></div>
    <div class="swiper__slide"><img src="/media/mkw/select04.png" style="width:100%;"></div>
    <div class="swiper__slide"><img src="/media/mkw/select01.png" style="width:100%;"></div>
    <div class="swiper__slide"><img src="/media/mkw/select02.png" style="width:100%;"></div>
  </div>
  <!-- <div class="swiper__pagination"></div> -->
  <div class="swiper__button swiper__button--prev fas fa-chevron-left"></div>
  <div class="swiper__button swiper__button--next fas fa-chevron-right"></div>
  <!-- <div class="swiper-scrollbar"></div> -->
</div> -->

<center><a href='/media/mkw/parallel.html'><img width="100%" src="/media/mkw/select03.png"></a></center>


The routine can be found in [this file](https://github.com/Chipdelmal/MKW_ParallelPlot/blob/main/main.py) and the interactive live version can be checked out [here!](/media/mkw/parallel.html)

## Radar Plot

One final thing I wanted to try out was to create a simple application to compare builds one against the other. For this, I coded up a [Dash](https://dash.plotly.com/) front-end with a [plotly](https://plotly.com/python/) radar plot. I won't go into much detail in how the UI and plots were created as it's not all too fancy, but all the code can be found [here](https://github.com/Chipdelmal/MKW_ParallelPlot/blob/main/radar.py):

<center><img width="45%" src="/media/mkw/radar.png"></center>


# Optimum Combo?

[Mario Kart World](https://www.nintendo.com/us/store/products/mario-kart-world-switch-2/?srsltid=AfmBOor1qRSsk4Afg6UtUKV8_qoM5ySLO1iM22xT2n3SV-hpe4kxBDJE) is quite different from [Mario Kart 8 Deluxe](https://mariokart8.nintendo.com/) in the fact that there are more hidden stats and a variety of routes/track styles. This makes for a situation in which there is no pareto optimal combination, as one set can be extremely good in solid ground, but terrible in water. That being said, I have found the super vanilla `Yoshi + Standard Kart` to be a good all-rounder to get started and learn the ropes of the game.

# Future Work

One avenue I haven't quite explored is to use the distances between the stats vectors as another way to measure similarity between combos. This would have the benefit over the clusters in that it would show us a numerical metric of separation between combinations. The distances should be easy to calculate as follows:

```python
if MDISTANCE=='cosine':
    mfun = cosine_distances
elif MDISTANCE=='manhattan':
    mfun = manhattan_distances
else:
    mfun = euclidean_distances
pairs = list(dfCmb.index)[:]
pkl.dump(pairs, open(path.join(PT_CLS, 'lst_combos.pkl'), 'wb'))
# Generate matrix -------------------------------------------------------------
mat = []
for i in tqdm(pairs):
    cRow = mfun(np.array([dfCmb.loc[i]]), np.array(dfCmb))[0]
    mat.append(cRow)
mat = np.array(mat)
np.save(path.join(PT_CLS, f'mat_{MDISTANCE}.npy'), mat)
```

Maybe in the near future I will look at this option in more detail.

# Code Repo and Data Sources

* Repository: [GitHub Repo](https://github.com/Chipdelmal/MKW_ParallelPlot)
* Dependencies: [hiplot](https://facebookresearch.github.io/hiplot/), [matplotlib](https://matplotlib.org/), [pandas](https://pandas.pydata.org/), [numpy](https://numpy.org/), [scikit-learn](https://scikit-learn.org/stable/)
* Data Sources: [bento, LastExceed](https://docs.google.com/spreadsheets/d/1t3BeXH3shj6Rh7x0ROFD81ZBxyumQFs9pebbnYcfWi4/edit?gid=735843013#gid=735843013), [CrypticJacknife](https://docs.google.com/spreadsheets/d/1RDVXylUbESnTypSjsz9ZAnpFE7soSeoIy2ySQgr3Moc/edit?gid=0#gid=0), [Delta](https://docs.google.com/spreadsheets/d/1vzXFXLVysdrzsanU4sxJaiDQ8OyA_xmMtBTyZcuSsh4/edit?gid=301238639#gid=301238639), [AprilShade, LBRZ](https://docs.google.com/spreadsheets/d/1mJpPleFFDilD_w_kk3v1vlpgd-vyXm8rX8XiDtKlB0k/edit?gid=297758703#gid=297758703), [pop2pop](https://docs.google.com/spreadsheets/d/1lTJHVtyrR0eZHCarJIVF3pkcxB-sTGbV/edit?gid=735843013#gid=735843013), [Luigi_Fan2](https://docs.google.com/spreadsheets/d/1BtHeFAEwL1MLND-l7KZz_Zg4wZWC2YIikbyweocqwSs/edit?gid=0#gid=0), [brad.wheeler](https://public.tableau.com/app/profile/brad.wheeler/viz/MarioKartWorldStats/MarioKartWorld)